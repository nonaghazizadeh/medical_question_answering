{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJqzpH5Yn9dz"
      },
      "source": [
        "<div dir='rtl' style='direction:rtl:'>\n",
        "\n",
        "# جست و جوی برداری بوسیله ی Elastic Search\n",
        "در این بخش،\n",
        "به ساخت دیتابیس،\n",
        "افزودن امبدینگ های تولید شده\n",
        "و جست و جوی امبدینگ درخواستی در میان\n",
        "امبدینگ های ذخیره شده می پردازیم.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97H7b74Sn1Jp",
        "outputId": "d5450481-d394-47cf-cb56-15859806fd97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.6/28.6 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m913.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install elasticsearch==7.13.0 transformers tensorflow-io -q\n",
        "!pip install -U sentence-transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpBDZCXMoN0s",
        "outputId": "0ceed608-5f2e-4c2e-91c9-7fe4c7196fda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m61.4/64.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow -q\n",
        "# !pip install tensorflow_text -q\n",
        "# !pip install tensorflow_hub -q\n",
        "!pip install elasticsearch_dsl -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6AiYbvDSzG3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from elasticsearch import Elasticsearch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "import tensorflow_io as tfio\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "# import tensorflow_text as text\n",
        "from elasticsearch import Elasticsearch, helpers\n",
        "from elasticsearch_dsl import Search, Q\n",
        "import hashlib\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "from tqdm import tqdm_notebook\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CFBKatfS095",
        "outputId": "b2d15348-3bdd-45a6-b2de-6ea48953833d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensorflow-io version: 0.33.0\n",
            "tensorflow version: 2.12.0\n"
          ]
        }
      ],
      "source": [
        "print(\"tensorflow-io version: {}\".format(tfio.__version__))\n",
        "print(\"tensorflow version: {}\".format(tf.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exw_5u6tTuwc"
      },
      "source": [
        "<div dir='rtl' style='direction:rtl:'>\n",
        "\n",
        "#  تنطیم اولیه Elastic Search\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKXgcULVS3XR",
        "outputId": "1249cbbd-220c-4b1e-ae7e-dfb81a0e863f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "elasticsearch-oss-7.9.2-linux-x86_64.tar.gz: OK\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz\n",
        "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512\n",
        "tar -xzf elasticsearch-oss-7.9.2-linux-x86_64.tar.gz\n",
        "sudo chown -R daemon:daemon elasticsearch-7.9.2/\n",
        "shasum -a 512 -c elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf_ifrgAS5e7"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -H -u daemon elasticsearch-7.9.2/bin/elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqWsnsLcS7MD",
        "outputId": "899c69d7-5f2a-405c-ac14-afc7b6860e7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root         981     979  0 15:43 ?        00:00:00 sudo -H -u daemon elasticsearch-7.9.2/bin/elasticsearch\n",
            "daemon       983     981  7 15:43 ?        00:00:00 /content/elasticsearch-7.9.2/jdk/bin/java -Xshare:auto -Des.networkaddress.cache.ttl=60 -Des.networkaddress.cache.negative.ttl=10 -XX:+AlwaysPreTouch -Xss1m -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -XX:-OmitStackTraceInFastThrow -XX:+ShowCodeDetailsInExceptionMessages -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 -Dio.netty.allocator.numDirectArenas=0 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.locale.providers=SPI,COMPAT -Xms1g -Xmx1g -XX:+UseG1GC -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -Djava.io.tmpdir=/tmp/elasticsearch-14600612574893112464 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=data -XX:ErrorFile=logs/hs_err_pid%p.log -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m -XX:MaxDirectMemorySize=536870912 -Des.path.home=/content/elasticsearch-7.9.2 -Des.path.conf=/content/elasticsearch-7.9.2/config -Des.distribution.flavor=oss -Des.distribution.type=tar -Des.bundled_jdk=true -cp /content/elasticsearch-7.9.2/lib/* org.elasticsearch.bootstrap.Elasticsearch\n",
            "root        1199    1197  0 15:44 ?        00:00:00 grep elasticsearch\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "ps -ef | grep elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft07CI9fS8_a",
        "outputId": "8c14c68d-bbb8-4180-f17e-9356550f0f35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"name\" : \"d24bbb2c6b6c\",\n",
            "  \"cluster_name\" : \"elasticsearch\",\n",
            "  \"cluster_uuid\" : \"YRullyRiSRKstNGllpqpMw\",\n",
            "  \"version\" : {\n",
            "    \"number\" : \"7.9.2\",\n",
            "    \"build_flavor\" : \"oss\",\n",
            "    \"build_type\" : \"tar\",\n",
            "    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n",
            "    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n",
            "    \"build_snapshot\" : false,\n",
            "    \"lucene_version\" : \"8.6.2\",\n",
            "    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n",
            "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
            "  },\n",
            "  \"tagline\" : \"You Know, for Search\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "curl -sX GET \"localhost:9200/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLttkaTcoig1",
        "outputId": "c31f4007-06a4-4860-da5e-c9689aa7d066"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "\n",
        "ES_NODES = \"http://localhost:9200/\"\n",
        "es = Elasticsearch(hosts = [ES_NODES])\n",
        "\n",
        "index_name = 'biobert_embeddings'\n",
        "\n",
        "if not es.indices.exists(index=index_name):\n",
        "    es.indices.create(index=index_name)\n",
        "\n",
        "time.sleep(30)\n",
        "es.ping()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK2lmWEjdENe",
        "outputId": "7f8ef4d0-bcbc-4af9-8077-e3b824b6e46d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "yellow open biobert_embeddings peZp2GQtT6G-6vIVYFeWTA 1 1 0 0 208b 208b\n",
            "\n"
          ]
        }
      ],
      "source": [
        "create_response = es.cat.indices() #print new index list\n",
        "print(create_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHtspfJuVwp3",
        "outputId": "4156b33a-05a0-4f94-c49e-7707d4522295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'name': '61987699fead', 'cluster_name': 'elasticsearch', 'cluster_uuid': 'vylcWat6Qo-2jqmqYf3Log', 'version': {'number': '7.9.2', 'build_flavor': 'oss', 'build_type': 'tar', 'build_hash': 'd34da0ea4a966c4e49417f2da2f244e3e97b4e6e', 'build_date': '2020-09-23T00:45:33.626720Z', 'build_snapshot': False, 'lucene_version': '8.6.2', 'minimum_wire_compatibility_version': '6.8.0', 'minimum_index_compatibility_version': '6.0.0-beta1'}, 'tagline': 'You Know, for Search'}\n"
          ]
        }
      ],
      "source": [
        "print(es.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ktw_RFBUpKi"
      },
      "outputs": [],
      "source": [
        "#drive\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tJej_MJUK3A"
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENRKWxjnH1H8"
      },
      "outputs": [],
      "source": [
        "download = drive.CreateFile({'id': '1vx89vDIvGtc5w_kGp_T2OtCYDSnvhAEn'})\n",
        "download.GetContentFile('pubmed_qa_labeled_train.csv')\n",
        "\n",
        "download = drive.CreateFile({'id': '1fZIhPjl2SOpteFgIZ3l4pMizf-Aht7vL'})\n",
        "download.GetContentFile('concatenated_embedding_labeled_sentence1.pt')\n",
        "\n",
        "download = drive.CreateFile({'id': '17Ujs0azWlaaCha6T9F84JQIplOs4xRfr'})\n",
        "download.GetContentFile('concatenated_articles_labeled_sentence1.csv')\n",
        "\n",
        "download = drive.CreateFile({'id': '15EJMUm7oUZ-219JlLw9CprxQ0yr0Lk6n'})\n",
        "download.GetContentFile('sentence2_embedding.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRHl9f3ImvD3"
      },
      "outputs": [],
      "source": [
        "df_qa = pd.read_csv('/content/pubmed_qa_labeled_train.csv')\n",
        "concatenated_csv = pd.read_csv(\"/content/concatenated_articles_labeled_sentence1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A48ebKqpaT9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from elasticsearch import Elasticsearch, helpers\n",
        "import time\n",
        "\n",
        "es = Elasticsearch()\n",
        "\n",
        "BODY_INDEX_NAME = \"body_vectors\"\n",
        "BATCH_SIZE = 1000\n",
        "SEARCH_SIZE = 3\n",
        "\n",
        "df_samples = concatenated_csv\n",
        "# df_samples.rename(columns={\"pubid\": \"id\"}, inplace=True)\n",
        "\n",
        "embeddings = torch.load(\"/content/concatenated_embedding_labeled_sentence1.pt\")\n",
        "query_embeddings = torch.load(\"/content/sentence2_embedding.pt\")\n",
        "paper_ids = df_samples[\"pubid\"].tolist()\n",
        "\n",
        "\n",
        "def index_data(embeddings, paper_ids):  # Index the embeddings and their associated paper_ids\n",
        "    body_index_mapping = {\n",
        "        \"mappings\": {\n",
        "            \"properties\": {\n",
        "                \"body_text_vector\": {\"type\": \"dense_vector\", \"dims\": embeddings.shape[1]},\n",
        "                \"paper_id\": {\"type\": \"keyword\"}\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    es.indices.create(index=BODY_INDEX_NAME, body=body_index_mapping, ignore=400)\n",
        "\n",
        "    requests = []\n",
        "    for embedding, paper_id in zip(embeddings, paper_ids):\n",
        "        request = {\n",
        "            \"_op_type\": \"index\",\n",
        "            \"_index\": BODY_INDEX_NAME,\n",
        "            \"body_text_vector\": embedding.tolist(),\n",
        "            \"paper_id\": paper_id\n",
        "        }\n",
        "        requests.append(request)\n",
        "\n",
        "    indexing_start = time.time()\n",
        "    helpers.bulk(es, requests)\n",
        "    es.indices.refresh(index=BODY_INDEX_NAME)\n",
        "    indexing_time = time.time() - indexing_start\n",
        "\n",
        "    print(\"Done indexing. Indexing time: {:.2f} seconds.\".format(indexing_time))\n",
        "\n",
        "def get_random_query_embedding():\n",
        "    query_embeddings = torch.load(\"/content/sentence2_embedding.pt\")\n",
        "    question_number = np.random.randint(len(query_embeddings))\n",
        "    return np.array(query_embeddings[question_number]), question_number\n",
        "\n",
        "def run_query_loop():\n",
        "    for i in range(1):\n",
        "        try:\n",
        "            handle_query()\n",
        "        except KeyboardInterrupt:\n",
        "            return\n",
        "\n",
        "def handle_query():\n",
        "    # take embedding\n",
        "    query_embeddings = torch.load(\"/content/sentence2_embedding.pt\")\n",
        "    question_number = np.random.randint(len(query_embeddings))\n",
        "    query_embedding = np.array(query_embeddings[question_number])\n",
        "\n",
        "    search_start = time.time()\n",
        "\n",
        "    response = es.search(\n",
        "        index=BODY_INDEX_NAME,\n",
        "        body={\n",
        "            \"size\": BATCH_SIZE,\n",
        "            \"query\": {\"match_all\": {}},\n",
        "            \"_source\": {\"includes\": []},\n",
        "            \"docvalue_fields\": [\"paper_id\", \"body_text_vector\"]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    search_time = time.time() - search_start\n",
        "\n",
        "    results = []\n",
        "    for hit in response[\"hits\"][\"hits\"][:SEARCH_SIZE]:\n",
        "        doc_vector = np.array(hit[\"fields\"][\"body_text_vector\"])\n",
        "\n",
        "        query_embedding = query_embedding.reshape(1, -1)\n",
        "        doc_vector = doc_vector.reshape(1, -1)\n",
        "\n",
        "\n",
        "\n",
        "        similarity = np.dot(query_embedding, doc_vector.T) / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_vector))\n",
        "\n",
        "        print(query_embedding)\n",
        "        print(doc_vector)\n",
        "        print(similarity)\n",
        "\n",
        "\n",
        "        results.append((hit[\"fields\"][\"paper_id\"][0], similarity[0][0]))\n",
        "\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    print()\n",
        "    print(\"{} total hits.\".format(len(results)))\n",
        "    print(\"search time: {:.2f} ms\".format(search_time * 1000))\n",
        "\n",
        "    question_text = df_qa.loc[question_number, \"question\"]\n",
        "    print(\"Query: \", question_text)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    for paper_id, similarity in results[:SEARCH_SIZE]:\n",
        "        abstract = df_samples[df_samples[\"pubid\"] == paper_id][\"context\"].values[0]\n",
        "        print(\"abstract:\", abstract)\n",
        "        print(\"paper_id: {}, similarity: {:.4f}\".format(paper_id, similarity))\n",
        "        print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sXEMq_4uddR"
      },
      "outputs": [],
      "source": [
        "\n",
        "index_data(embeddings, paper_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Xo-Tfw6qufFq"
      },
      "outputs": [],
      "source": [
        "run_query_loop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}